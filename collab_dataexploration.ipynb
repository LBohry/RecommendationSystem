{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_info = pd.read_csv('studentInfo.csv')\n",
    "student_assessment = pd.read_csv('studentAssessment.csv')\n",
    "student_vle = pd.read_csv('studentVle.csv')\n",
    "vle = pd.read_csv('vle.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_info = student_info[['code_module', 'code_presentation', 'id_student', 'gender', 'region', 'highest_education', 'imd_band', 'age_band', 'num_of_prev_attempts', 'disability']]\n",
    "student_assessment = student_assessment[['id_student', 'id_assessment', 'date_submitted', 'is_banked', 'score']]\n",
    "student_vle = student_vle[['code_module', 'code_presentation', 'id_student', 'id_site', 'sum_click']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(student_info, student_assessment, on='id_student', how='inner')\n",
    "merged_df = pd.merge(merged_df, student_vle, on=['id_student', 'code_module', 'code_presentation'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = merged_df.groupby(['id_student', 'code_module', 'code_presentation', 'id_site']).agg({\n",
    "    'gender': 'first',\n",
    "    'region': 'first',\n",
    "    'highest_education': 'first',\n",
    "    'imd_band': 'first',\n",
    "    'age_band': 'first',\n",
    "    'num_of_prev_attempts' : 'first',\n",
    "    'disability': 'first',\n",
    "    'id_assessment': 'first',\n",
    "    'date_submitted': 'first',\n",
    "    'is_banked': 'first',\n",
    "    'score': 'first',\n",
    "    'sum_click': 'sum'\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#size of the data\n",
    "print(\"Number of rows: \", grouped_df.shape[0])\n",
    "print(\"Number of columns: \", grouped_df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking missing values\n",
    "print(grouped_df.isnull().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imd_band 106942 missing values / score 352 missing values, we may drop imd_band and try to use the median or mean for score, we'll see what we'll do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the distribution of each column using histograms\n",
    "included_cols = ['num_of_prev_attempts','score','sum_click','is_banked','date_submitted']\n",
    "grouped_df[included_cols].hist(figsize=(15, 15), bins=30)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#redisplay the sum_clicks data because it's unclear\n",
    "plt.hist(grouped_df[\"sum_click\"], bins=100, range=(0, 1000))\n",
    "plt.title(\"Distribution of Sum Clicks\")\n",
    "plt.xlabel(\"Sum Clicks\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check chbehom 50000 jeybin 0 score, why ?\n",
    "score_zero_df = grouped_df[grouped_df['score'] == 0]\n",
    "included_cols = ['highest_education', 'imd_band', 'age_band', 'num_of_prev_attempts', 'sum_click', 'is_banked', 'date_submitted', 'gender', 'region', 'disability']\n",
    "\n",
    "score_zero_df[included_cols].hist(figsize=(15, 15), bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the distribution of each categorical column using bar plots\n",
    "categorical_vars = ['highest_education', 'imd_band', 'age_band', 'gender', 'region', 'disability']\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axs = axs.flatten()\n",
    "\n",
    "for i, var in enumerate(categorical_vars):\n",
    "    grouped_df[var].value_counts().plot(kind='bar', ax=axs[i])\n",
    "    axs[i].set_title(var)\n",
    "    axs[i].set_xlabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there are extreme values in date_submitted, -11 to 608 , we've set it to 0 & 365\n",
    "df_cleaned = grouped_df[(grouped_df['date_submitted'] >= 0) & (grouped_df['date_submitted'] <= 365)]\n",
    "\n",
    "#there is quite a lot of people with 0 score, that would mean that those are mostly not engaged, therefore they'd provide bias in our model so we'll exclude them\n",
    "df_cleaned = df_cleaned[df_cleaned['score'] > 0]\n",
    "\n",
    "#drop the observations with missing score values : 352 missing values\n",
    "df_cleaned.dropna(subset=['score'], inplace=True)\n",
    "\n",
    "print(df_cleaned.shape)\n",
    "print(df_cleaned.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# Select the columns to include in the correlation analysis\n",
    "cols = ['highest_education', 'imd_band', 'age_band', 'num_of_prev_attempts',\n",
    "        'sum_click', 'is_banked', 'date_submitted', 'gender', 'region',\n",
    "        'disability','score']\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr = df_cleaned[cols].corr()\n",
    "\n",
    "# Visualize the correlation matrix using a heatmap\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is data preparation steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LET'S TREAT MISSING VALUES : imd_band 106611 missing values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define functions for converting between imd_band and percentage\n",
    "def convert_imd_band(imd_band):\n",
    "    if imd_band == '0-10%':\n",
    "        return 0\n",
    "    elif imd_band == '10-20':\n",
    "        return 1\n",
    "    elif imd_band == '20-30%':\n",
    "        return 2\n",
    "    elif imd_band == '30-40%':\n",
    "        return 3\n",
    "    elif imd_band == '40-50%':\n",
    "        return 4\n",
    "    elif imd_band == '50-60%':\n",
    "        return 5\n",
    "    elif imd_band == '60-70%':\n",
    "        return 6\n",
    "    elif imd_band == '70-80%':\n",
    "        return 7\n",
    "    elif imd_band == '80-90%':\n",
    "        return 8\n",
    "    elif imd_band == '90-100%':\n",
    "        return 9\n",
    "\n",
    "\n",
    "# categorical columns in the data\n",
    "cat_cols = ['code_module', 'code_presentation', 'gender', 'region', 'highest_education', 'age_band', 'disability']\n",
    "\n",
    "# Split the data into two parts: one with missing values in imd_band, and another with no missing values\n",
    "df_missing = df_cleaned[df_cleaned['imd_band'].isna()]\n",
    "df_not_missing = df_cleaned[~df_cleaned['imd_band'].isna()]\n",
    "\n",
    "# Split df_not_missing into train and test sets\n",
    "X_train, X_test, y_train_cat, y_test_cat = train_test_split(df_not_missing.drop('imd_band', axis=1), df_not_missing['imd_band'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert categorical values to numerical values\n",
    "y_train = y_train_cat.apply(convert_imd_band)\n",
    "y_test = y_test_cat.apply(convert_imd_band)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "# categorical columns in the data\n",
    "cat_cols = ['code_module', 'code_presentation', 'gender', 'region', 'highest_education', 'age_band', 'disability']\n",
    "\n",
    "# initialize the encoder\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "# fit the encoder on the categorical columns of the training data\n",
    "encoder.fit(X_train[cat_cols])\n",
    "\n",
    "# transform the categorical columns of the training and test data\n",
    "X_train_encoded = encoder.transform(X_train[cat_cols])\n",
    "X_test_encoded = encoder.transform(X_test[cat_cols])\n",
    "df_missing_encoded = encoder.transform(df_missing[cat_cols])\n",
    "\n",
    "# get the names of the encoded columns\n",
    "cat_col_names = encoder.get_feature_names_out(cat_cols)\n",
    "\n",
    "# concatenate the encoded columns with the non-categorical columns\n",
    "X_train_processed = np.concatenate((X_train_encoded, X_train.drop(cat_cols, axis=1)), axis=1)\n",
    "X_test_processed = np.concatenate((X_test_encoded, X_test.drop(cat_cols, axis=1)), axis=1)\n",
    "df_missing_processed = np.concatenate((df_missing_encoded, df_missing.drop(cat_cols + ['imd_band'], axis=1)), axis=1)\n",
    "\n",
    "# print the first five rows of the processed training data\n",
    "print(X_train_processed[:5])\n",
    "# print the column names of the processed training data\n",
    "col_names = np.concatenate((cat_col_names, X_train.drop(cat_cols, axis=1).columns))\n",
    "print(col_names)\n",
    "\n",
    "\n",
    "\n",
    "df_missing_processed_df = pd.DataFrame(data=df_missing_processed, columns=col_names)\n",
    "df_missing_processed_df.head(300)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##      import pandas as pd\n",
    "##      loaded_data = pd.read_csv('df_full_cleaned_predicted_imdband')\n",
    "##      \n",
    "##      demo_features = ['id_student', 'gender', 'region', 'highest_education', 'imd_band', 'age_band', 'studied_credits', 'disability']\n",
    "##      perf_features = ['code_module', 'code_presentation', 'id_assignment', 'score', 'is_banked', 'num_of_prev_attempts', 'final_result']\n",
    "##      \n",
    "##      additional_demo_data = pd.read_csv('studentInfo.csv')\n",
    "##      \n",
    "##      added_features = additional_demo_data[['id_student', 'code_module', 'code_presentation', 'final_result', 'studied_credits']]\n",
    "##      \n",
    "##      added_features = pd.get_dummies(added_features, columns=['code_module', 'code_presentation'], prefix=['code_module', 'code_presentation'])\n",
    "##      # Merge the student information data with the original DataFrame\n",
    "##      demopref_data = pd.merge(loaded_data, added_features, on=['id_student', 'code_presentation_2013B','code_presentation_2013J','code_presentation_2014B','code_presentation_2014J', 'code_module_AAA','code_module_BBB','code_module_CCC','code_module_DDD','code_module_EEE','code_module_FFF','code_module_GGG' ] )\n",
    "##      \n",
    "##      # Drop the irrelevant columns\n",
    "##      demopref_data.drop(['sum_click', 'id_site'], axis=1, inplace=True)\n",
    "##      demopref_data = pd.get_dummies(demopref_data, columns=['final_result'], prefix='final_result')\n",
    "##      demopref_data['id_student'] = demopref_data['id_student'].astype(int)\n",
    "##      demopref_data['id_assessment'] = demopref_data['id_assessment'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_features = X_train_encoded.shape\n",
    "n_samples, n_features_processed = X_train_processed.shape\n",
    "print(f\"Training set contains {n_samples} samples and {n_features} features.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the processed training and test data\n",
    "X_processed = np.concatenate((X_train_processed, X_test_processed), axis=0)\n",
    "X_processed_df = pd.DataFrame(X_processed, columns=col_names)\n",
    "\n",
    "y_processed = np.concatenate((y_train, y_test), axis=0)\n",
    "\n",
    "# concatenate the original non-missing data and the processed missing data\n",
    "df_not_missing_processed = pd.concat([X_processed_df, pd.DataFrame(data=y_processed, columns=['imd_band'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_processed.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USER-ITEM MATRIX : Relevant Features : code_module,code_presentation,id_student,id_site,activity_type,date,sum_click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "student_info = pd.read_csv('studentInfo.csv')\n",
    "student_vle = pd.read_csv('studentVle.csv')\n",
    "vle = pd.read_csv('vle.csv')\n",
    "\n",
    "\n",
    "U_I_student_info = student_info[['code_module', 'code_presentation', 'id_student']]\n",
    "U_I_student_vle = student_vle[['code_module', 'code_presentation', 'id_student', 'id_site', 'date', 'sum_click']]\n",
    "U_I_vle = vle[['id_site','activity_type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_I_merged_df = pd.merge(U_I_student_info, U_I_student_vle, on=['code_module', 'code_presentation', 'id_student'], how='inner')\n",
    "U_I_merged_df = pd.merge(U_I_merged_df, U_I_vle, on=['id_site'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User-item matrix : sum_click || we're also using aggfunc='sum' to group by basically\n",
    "user_item_matrix = pd.pivot_table(U_I_merged_df, values='sum_click', index='id_student', columns='id_site', aggfunc='sum', fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEMOGRAPHICS + PERFORMANCE Based Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "loaded_data = pd.read_csv('df_full_cleaned_predicted_imdband')\n",
    "\n",
    "demo_features = ['id_student', 'gender', 'region', 'highest_education', 'imd_band', 'age_band', 'studied_credits', 'disability']\n",
    "perf_features = ['code_module', 'code_presentation', 'id_assignment', 'score', 'is_banked', 'num_of_prev_attempts', 'final_result']\n",
    "\n",
    "additional_demo_data = pd.read_csv('studentInfo.csv')\n",
    "\n",
    "added_features = additional_demo_data[['id_student', 'code_module', 'code_presentation', 'final_result', 'studied_credits']]\n",
    "\n",
    "added_features = pd.get_dummies(added_features, columns=['code_module', 'code_presentation'], prefix=['code_module', 'code_presentation'])\n",
    "# Merge the student information data with the original DataFrame\n",
    "demopref_data = pd.merge(loaded_data, added_features, on=['id_student', 'code_presentation_2013B','code_presentation_2013J','code_presentation_2014B','code_presentation_2014J', 'code_module_AAA','code_module_BBB','code_module_CCC','code_module_DDD','code_module_EEE','code_module_FFF','code_module_GGG' ] )\n",
    "\n",
    "# Drop the irrelevant columns\n",
    "demopref_data.drop(['sum_click', 'id_site'], axis=1, inplace=True)\n",
    "demopref_data = pd.get_dummies(demopref_data, columns=['final_result'], prefix='final_result')\n",
    "demopref_data['id_student'] = demopref_data['id_student'].astype(int)\n",
    "demopref_data['id_assessment'] = demopref_data['id_assessment'].astype(int)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
