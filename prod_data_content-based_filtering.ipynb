{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "Dataset = pd.read_csv('Global_elearning_Quantia.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HEADLINE</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>CORE_CONTENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66 yo w/ Chronic, Worsening Foot Pain</td>\n",
       "      <td>Which of the following findings are demonstrat...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bloody Stools in the NICU</td>\n",
       "      <td>What is your differential diagnosis? Necrotizi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Erectile Dysfunction and Cardiovascular Risk</td>\n",
       "      <td>Expert presentation on erectile dysfunction an...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cost Effectiveness in Sexual Medicine – Tales ...</td>\n",
       "      <td>Case presentation on the erectile dysfucntion ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A 46 year old lady with joint pain</td>\n",
       "      <td>An image challenge on a 46 year old lady with ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            HEADLINE  \\\n",
       "0              66 yo w/ Chronic, Worsening Foot Pain   \n",
       "1                          Bloody Stools in the NICU   \n",
       "2       Erectile Dysfunction and Cardiovascular Risk   \n",
       "3  Cost Effectiveness in Sexual Medicine – Tales ...   \n",
       "4                 A 46 year old lady with joint pain   \n",
       "\n",
       "                                         DESCRIPTION CORE_CONTENT  \n",
       "0  Which of the following findings are demonstrat...          NaN  \n",
       "1  What is your differential diagnosis? Necrotizi...          NaN  \n",
       "2  Expert presentation on erectile dysfunction an...          NaN  \n",
       "3  Case presentation on the erectile dysfucntion ...          NaN  \n",
       "4  An image challenge on a 46 year old lady with ...          NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HEADLINE : like a title of the course \n",
    "### DESCRIPTION : self explanatory \n",
    "### CORE_CONTENT : describing the teacher"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning : removing duplicates, whitespaces, removing the html tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset['HEADLINE'] = Dataset['HEADLINE'].str.strip()\n",
    "Dataset['DESCRIPTION'] = Dataset['DESCRIPTION'].str.strip()\n",
    "Dataset['CORE_CONTENT'] = Dataset['CORE_CONTENT'].str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset = Dataset.drop_duplicates()\n",
    "Dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEADLINE                    66 yo w/ Chronic, Worsening Foot Pain\n",
      "DESCRIPTION     Which of the following findings are demonstrat...\n",
      "CORE_CONTENT                                                  NaN\n",
      "Name: 0, dtype: object\n",
      "HEADLINE                    66 yo w/ Chronic, Worsening Foot Pain\n",
      "DESCRIPTION     Which of the following findings are demonstrat...\n",
      "CORE_CONTENT    <p><strong>Adnaan Moin, MD</strong><br />PGY-3...\n",
      "Name: 64, dtype: object\n",
      "HEADLINE                    66 yo w/ Chronic, Worsening Foot Pain\n",
      "DESCRIPTION     Which of the following findings are demonstrat...\n",
      "CORE_CONTENT    <p><strong>Adnaan Moin, MD</strong><br>PGY-3, ...\n",
      "Name: 117, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(Dataset.loc[0])\n",
    "print(Dataset.loc[64])\n",
    "print(Dataset.loc[117])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset = Dataset.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_cleaned = Dataset\n",
    "Dataset_cleaned['CORE_CONTENT'] = Dataset_cleaned['CORE_CONTENT'].replace(to_replace='<br/>', value=', ', regex=True)\n",
    "Dataset_cleaned['CORE_CONTENT'] = Dataset_cleaned['CORE_CONTENT'].str.replace(r'<[^<>]*>', '', regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HEADLINE                     63 yo M w/ Sudden Left Arm Paralysis\n",
       "DESCRIPTION     Rikki Racela, MD presents the case of a 63 yo ...\n",
       "CORE_CONTENT    Rikki Racela, MDNeurologist, Bergen Neurology ...\n",
       "Name: 36, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset_cleaned.loc[36,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercasing the data\n",
    "Dataset_cleaned['HEADLINE_Lowercased'] = Dataset_cleaned['HEADLINE'].str.lower()\n",
    "Dataset_cleaned['DESCRIPTION_Lowercased'] = Dataset_cleaned['DESCRIPTION'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HEADLINE</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>CORE_CONTENT</th>\n",
       "      <th>HEADLINE_Lowercased</th>\n",
       "      <th>DESCRIPTION_Lowercased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66 yo w/ Chronic, Worsening Foot Pain</td>\n",
       "      <td>Which of the following findings are demonstrat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66 yo w/ chronic, worsening foot pain</td>\n",
       "      <td>which of the following findings are demonstrat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bloody Stools in the NICU</td>\n",
       "      <td>What is your differential diagnosis? Necrotizi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bloody stools in the nicu</td>\n",
       "      <td>what is your differential diagnosis? necrotizi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Erectile Dysfunction and Cardiovascular Risk</td>\n",
       "      <td>Expert presentation on erectile dysfunction an...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>erectile dysfunction and cardiovascular risk</td>\n",
       "      <td>expert presentation on erectile dysfunction an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cost Effectiveness in Sexual Medicine – Tales ...</td>\n",
       "      <td>Case presentation on the erectile dysfucntion ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cost effectiveness in sexual medicine – tales ...</td>\n",
       "      <td>case presentation on the erectile dysfucntion ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A 46 year old lady with joint pain</td>\n",
       "      <td>An image challenge on a 46 year old lady with ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a 46 year old lady with joint pain</td>\n",
       "      <td>an image challenge on a 46 year old lady with ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            HEADLINE  \\\n",
       "0              66 yo w/ Chronic, Worsening Foot Pain   \n",
       "1                          Bloody Stools in the NICU   \n",
       "2       Erectile Dysfunction and Cardiovascular Risk   \n",
       "3  Cost Effectiveness in Sexual Medicine – Tales ...   \n",
       "4                 A 46 year old lady with joint pain   \n",
       "\n",
       "                                         DESCRIPTION CORE_CONTENT  \\\n",
       "0  Which of the following findings are demonstrat...          NaN   \n",
       "1  What is your differential diagnosis? Necrotizi...          NaN   \n",
       "2  Expert presentation on erectile dysfunction an...          NaN   \n",
       "3  Case presentation on the erectile dysfucntion ...          NaN   \n",
       "4  An image challenge on a 46 year old lady with ...          NaN   \n",
       "\n",
       "                                 HEADLINE_Lowercased  \\\n",
       "0              66 yo w/ chronic, worsening foot pain   \n",
       "1                          bloody stools in the nicu   \n",
       "2       erectile dysfunction and cardiovascular risk   \n",
       "3  cost effectiveness in sexual medicine – tales ...   \n",
       "4                 a 46 year old lady with joint pain   \n",
       "\n",
       "                              DESCRIPTION_Lowercased  \n",
       "0  which of the following findings are demonstrat...  \n",
       "1  what is your differential diagnosis? necrotizi...  \n",
       "2  expert presentation on erectile dysfunction an...  \n",
       "3  case presentation on the erectile dysfucntion ...  \n",
       "4  an image challenge on a 46 year old lady with ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Abirr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HEADLINE</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>CORE_CONTENT</th>\n",
       "      <th>HEADLINE_Lowercased</th>\n",
       "      <th>DESCRIPTION_Lowercased</th>\n",
       "      <th>HEADLINE_tokens</th>\n",
       "      <th>DESCRIPTION_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66 yo w/ Chronic, Worsening Foot Pain</td>\n",
       "      <td>Which of the following findings are demonstrat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66 yo w/ chronic, worsening foot pain</td>\n",
       "      <td>which of the following findings are demonstrat...</td>\n",
       "      <td>[66, yo, w/, chronic, ,, worsening, foot, pain]</td>\n",
       "      <td>[which, of, the, following, findings, are, dem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bloody Stools in the NICU</td>\n",
       "      <td>What is your differential diagnosis? Necrotizi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bloody stools in the nicu</td>\n",
       "      <td>what is your differential diagnosis? necrotizi...</td>\n",
       "      <td>[bloody, stools, in, the, nicu]</td>\n",
       "      <td>[what, is, your, differential, diagnosis, ?, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Erectile Dysfunction and Cardiovascular Risk</td>\n",
       "      <td>Expert presentation on erectile dysfunction an...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>erectile dysfunction and cardiovascular risk</td>\n",
       "      <td>expert presentation on erectile dysfunction an...</td>\n",
       "      <td>[erectile, dysfunction, and, cardiovascular, r...</td>\n",
       "      <td>[expert, presentation, on, erectile, dysfuncti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cost Effectiveness in Sexual Medicine – Tales ...</td>\n",
       "      <td>Case presentation on the erectile dysfucntion ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cost effectiveness in sexual medicine – tales ...</td>\n",
       "      <td>case presentation on the erectile dysfucntion ...</td>\n",
       "      <td>[cost, effectiveness, in, sexual, medicine, –,...</td>\n",
       "      <td>[case, presentation, on, the, erectile, dysfuc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A 46 year old lady with joint pain</td>\n",
       "      <td>An image challenge on a 46 year old lady with ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a 46 year old lady with joint pain</td>\n",
       "      <td>an image challenge on a 46 year old lady with ...</td>\n",
       "      <td>[a, 46, year, old, lady, with, joint, pain]</td>\n",
       "      <td>[an, image, challenge, on, a, 46, year, old, l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            HEADLINE  \\\n",
       "0              66 yo w/ Chronic, Worsening Foot Pain   \n",
       "1                          Bloody Stools in the NICU   \n",
       "2       Erectile Dysfunction and Cardiovascular Risk   \n",
       "3  Cost Effectiveness in Sexual Medicine – Tales ...   \n",
       "4                 A 46 year old lady with joint pain   \n",
       "\n",
       "                                         DESCRIPTION CORE_CONTENT  \\\n",
       "0  Which of the following findings are demonstrat...          NaN   \n",
       "1  What is your differential diagnosis? Necrotizi...          NaN   \n",
       "2  Expert presentation on erectile dysfunction an...          NaN   \n",
       "3  Case presentation on the erectile dysfucntion ...          NaN   \n",
       "4  An image challenge on a 46 year old lady with ...          NaN   \n",
       "\n",
       "                                 HEADLINE_Lowercased  \\\n",
       "0              66 yo w/ chronic, worsening foot pain   \n",
       "1                          bloody stools in the nicu   \n",
       "2       erectile dysfunction and cardiovascular risk   \n",
       "3  cost effectiveness in sexual medicine – tales ...   \n",
       "4                 a 46 year old lady with joint pain   \n",
       "\n",
       "                              DESCRIPTION_Lowercased  \\\n",
       "0  which of the following findings are demonstrat...   \n",
       "1  what is your differential diagnosis? necrotizi...   \n",
       "2  expert presentation on erectile dysfunction an...   \n",
       "3  case presentation on the erectile dysfucntion ...   \n",
       "4  an image challenge on a 46 year old lady with ...   \n",
       "\n",
       "                                     HEADLINE_tokens  \\\n",
       "0    [66, yo, w/, chronic, ,, worsening, foot, pain]   \n",
       "1                    [bloody, stools, in, the, nicu]   \n",
       "2  [erectile, dysfunction, and, cardiovascular, r...   \n",
       "3  [cost, effectiveness, in, sexual, medicine, –,...   \n",
       "4        [a, 46, year, old, lady, with, joint, pain]   \n",
       "\n",
       "                                  DESCRIPTION_tokens  \n",
       "0  [which, of, the, following, findings, are, dem...  \n",
       "1  [what, is, your, differential, diagnosis, ?, n...  \n",
       "2  [expert, presentation, on, erectile, dysfuncti...  \n",
       "3  [case, presentation, on, the, erectile, dysfuc...  \n",
       "4  [an, image, challenge, on, a, 46, year, old, l...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenizing the data \n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "Dataset_cleaned['HEADLINE_tokens'] = Dataset_cleaned['HEADLINE_Lowercased'].apply(word_tokenize)\n",
    "Dataset_cleaned['DESCRIPTION_tokens'] = Dataset_cleaned['DESCRIPTION_Lowercased'].apply(word_tokenize)\n",
    "Dataset_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Abirr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HEADLINE</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>CORE_CONTENT</th>\n",
       "      <th>HEADLINE_Lowercased</th>\n",
       "      <th>DESCRIPTION_Lowercased</th>\n",
       "      <th>HEADLINE_tokens</th>\n",
       "      <th>DESCRIPTION_tokens</th>\n",
       "      <th>HEADLINE_noStop</th>\n",
       "      <th>DESCRIPTION_noStop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66 yo w/ Chronic, Worsening Foot Pain</td>\n",
       "      <td>Which of the following findings are demonstrat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66 yo w/ chronic, worsening foot pain</td>\n",
       "      <td>which of the following findings are demonstrat...</td>\n",
       "      <td>[66, yo, w/, chronic, ,, worsening, foot, pain]</td>\n",
       "      <td>[which, of, the, following, findings, are, dem...</td>\n",
       "      <td>[66, yo, w/, chronic, ,, worsening, foot, pain]</td>\n",
       "      <td>[following, findings, demonstrated, radiograph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bloody Stools in the NICU</td>\n",
       "      <td>What is your differential diagnosis? Necrotizi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bloody stools in the nicu</td>\n",
       "      <td>what is your differential diagnosis? necrotizi...</td>\n",
       "      <td>[bloody, stools, in, the, nicu]</td>\n",
       "      <td>[what, is, your, differential, diagnosis, ?, n...</td>\n",
       "      <td>[bloody, stools, nicu]</td>\n",
       "      <td>[differential, diagnosis, ?, necrotizing, ente...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Erectile Dysfunction and Cardiovascular Risk</td>\n",
       "      <td>Expert presentation on erectile dysfunction an...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>erectile dysfunction and cardiovascular risk</td>\n",
       "      <td>expert presentation on erectile dysfunction an...</td>\n",
       "      <td>[erectile, dysfunction, and, cardiovascular, r...</td>\n",
       "      <td>[expert, presentation, on, erectile, dysfuncti...</td>\n",
       "      <td>[erectile, dysfunction, cardiovascular, risk]</td>\n",
       "      <td>[expert, presentation, erectile, dysfunction, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cost Effectiveness in Sexual Medicine – Tales ...</td>\n",
       "      <td>Case presentation on the erectile dysfucntion ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cost effectiveness in sexual medicine – tales ...</td>\n",
       "      <td>case presentation on the erectile dysfucntion ...</td>\n",
       "      <td>[cost, effectiveness, in, sexual, medicine, –,...</td>\n",
       "      <td>[case, presentation, on, the, erectile, dysfuc...</td>\n",
       "      <td>[cost, effectiveness, sexual, medicine, –, tal...</td>\n",
       "      <td>[case, presentation, erectile, dysfucntion, ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A 46 year old lady with joint pain</td>\n",
       "      <td>An image challenge on a 46 year old lady with ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a 46 year old lady with joint pain</td>\n",
       "      <td>an image challenge on a 46 year old lady with ...</td>\n",
       "      <td>[a, 46, year, old, lady, with, joint, pain]</td>\n",
       "      <td>[an, image, challenge, on, a, 46, year, old, l...</td>\n",
       "      <td>[46, year, old, lady, joint, pain]</td>\n",
       "      <td>[image, challenge, 46, year, old, lady, joint,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            HEADLINE  \\\n",
       "0              66 yo w/ Chronic, Worsening Foot Pain   \n",
       "1                          Bloody Stools in the NICU   \n",
       "2       Erectile Dysfunction and Cardiovascular Risk   \n",
       "3  Cost Effectiveness in Sexual Medicine – Tales ...   \n",
       "4                 A 46 year old lady with joint pain   \n",
       "\n",
       "                                         DESCRIPTION CORE_CONTENT  \\\n",
       "0  Which of the following findings are demonstrat...          NaN   \n",
       "1  What is your differential diagnosis? Necrotizi...          NaN   \n",
       "2  Expert presentation on erectile dysfunction an...          NaN   \n",
       "3  Case presentation on the erectile dysfucntion ...          NaN   \n",
       "4  An image challenge on a 46 year old lady with ...          NaN   \n",
       "\n",
       "                                 HEADLINE_Lowercased  \\\n",
       "0              66 yo w/ chronic, worsening foot pain   \n",
       "1                          bloody stools in the nicu   \n",
       "2       erectile dysfunction and cardiovascular risk   \n",
       "3  cost effectiveness in sexual medicine – tales ...   \n",
       "4                 a 46 year old lady with joint pain   \n",
       "\n",
       "                              DESCRIPTION_Lowercased  \\\n",
       "0  which of the following findings are demonstrat...   \n",
       "1  what is your differential diagnosis? necrotizi...   \n",
       "2  expert presentation on erectile dysfunction an...   \n",
       "3  case presentation on the erectile dysfucntion ...   \n",
       "4  an image challenge on a 46 year old lady with ...   \n",
       "\n",
       "                                     HEADLINE_tokens  \\\n",
       "0    [66, yo, w/, chronic, ,, worsening, foot, pain]   \n",
       "1                    [bloody, stools, in, the, nicu]   \n",
       "2  [erectile, dysfunction, and, cardiovascular, r...   \n",
       "3  [cost, effectiveness, in, sexual, medicine, –,...   \n",
       "4        [a, 46, year, old, lady, with, joint, pain]   \n",
       "\n",
       "                                  DESCRIPTION_tokens  \\\n",
       "0  [which, of, the, following, findings, are, dem...   \n",
       "1  [what, is, your, differential, diagnosis, ?, n...   \n",
       "2  [expert, presentation, on, erectile, dysfuncti...   \n",
       "3  [case, presentation, on, the, erectile, dysfuc...   \n",
       "4  [an, image, challenge, on, a, 46, year, old, l...   \n",
       "\n",
       "                                     HEADLINE_noStop  \\\n",
       "0    [66, yo, w/, chronic, ,, worsening, foot, pain]   \n",
       "1                             [bloody, stools, nicu]   \n",
       "2      [erectile, dysfunction, cardiovascular, risk]   \n",
       "3  [cost, effectiveness, sexual, medicine, –, tal...   \n",
       "4                 [46, year, old, lady, joint, pain]   \n",
       "\n",
       "                                  DESCRIPTION_noStop  \n",
       "0  [following, findings, demonstrated, radiograph...  \n",
       "1  [differential, diagnosis, ?, necrotizing, ente...  \n",
       "2  [expert, presentation, erectile, dysfunction, ...  \n",
       "3  [case, presentation, erectile, dysfucntion, ca...  \n",
       "4  [image, challenge, 46, year, old, lady, joint,...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtering stop words\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "Dataset_cleaned['HEADLINE_noStop'] = Dataset_cleaned['HEADLINE_tokens'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "Dataset_cleaned['DESCRIPTION_noStop'] = Dataset_cleaned['DESCRIPTION_tokens'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "Dataset_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Abirr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Abirr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Lemmatization \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "Dataset_cleaned['HEADLINE_lemmatized'] = Dataset_cleaned['HEADLINE_noStop'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "Dataset_cleaned['DESCRIPTION_lemmatized'] = Dataset_cleaned['DESCRIPTION_noStop'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_cleaned = Dataset_cleaned.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the headline + description into one full text content column\n",
    "merged_full_text = []\n",
    "for i in range(Dataset_cleaned.shape[0]):\n",
    "    merged_full_text.append(' '.join(Dataset_cleaned['HEADLINE_lemmatized'][i]) + ' ' + ' '.join(Dataset_cleaned['DESCRIPTION_lemmatized'][i]))\n",
    "\n",
    "# add the concatenated text as a new column in the dataframe\n",
    "Dataset_cleaned['merged_full_text'] = merged_full_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                                                                    36\n",
       "HEADLINE                               63 yo M w/ Sudden Left Arm Paralysis\n",
       "DESCRIPTION               Rikki Racela, MD presents the case of a 63 yo ...\n",
       "CORE_CONTENT              Rikki Racela, MDNeurologist, Bergen Neurology ...\n",
       "HEADLINE_Lowercased                    63 yo m w/ sudden left arm paralysis\n",
       "DESCRIPTION_Lowercased    rikki racela, md presents the case of a 63 yo ...\n",
       "HEADLINE_tokens               [63, yo, m, w/, sudden, left, arm, paralysis]\n",
       "DESCRIPTION_tokens        [rikki, racela, ,, md, presents, the, case, of...\n",
       "HEADLINE_noStop                  [63, yo, w/, sudden, left, arm, paralysis]\n",
       "DESCRIPTION_noStop        [rikki, racela, ,, md, presents, case, 63, yo,...\n",
       "HEADLINE_lemmatized              [63, yo, w/, sudden, left, arm, paralysis]\n",
       "DESCRIPTION_lemmatized    [rikki, racela, ,, md, present, case, 63, yo, ...\n",
       "merged_full_text          63 yo w/ sudden left arm paralysis rikki racel...\n",
       "Name: 36, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset_cleaned.loc[36,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tokenize title_desc column\n",
    "Dataset_cleaned['merged_full_text_tokenized'] = Dataset_cleaned['merged_full_text'].apply(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Define a regular expression pattern to match non-alphanumeric characters\n",
    "pattern = r'[^a-zA-Z0-9\\s]'\n",
    "\n",
    "# Clean the tokens in each row of the 'title_desc_tokenized' column\n",
    "Dataset_cleaned['merged_full_text_cleaned'] = Dataset_cleaned['merged_full_text_tokenized'].apply(lambda tokens: [re.sub(pattern, '', token) for token in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Train the Word2Vec model\n",
    "wordembed_model = Word2Vec(Dataset_cleaned['merged_full_text_cleaned'], min_count=1, vector_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('vascular', 0.31842494010925293),\n",
       " ('f', 0.31561407446861267),\n",
       " ('would', 0.3047691881656647),\n",
       " ('yo', 0.28698182106018066),\n",
       " ('gaeta', 0.28407132625579834),\n",
       " ('w', 0.28072455525398254),\n",
       " ('expert', 0.28019219636917114),\n",
       " ('wound', 0.27626916766166687),\n",
       " ('', 0.2755339741706848),\n",
       " ('positivity', 0.273283451795578)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordembed_model.wv.most_similar('chronic')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 15)\n"
     ]
    }
   ],
   "source": [
    "Dataset_cleaned = Dataset_cleaned.drop_duplicates(subset='merged_full_text')\n",
    "print(Dataset_cleaned.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index of Dataset_cleaned\n",
    "Dataset_cleaned.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_len = max([len(np.concatenate([wordembed_model.wv[word] for word in row['merged_full_text_cleaned']])) for _, row in Dataset_cleaned.iterrows()])\n",
    "\n",
    "def get_padded_embedding(course_id : int):\n",
    "    course = Dataset_cleaned.loc[course_id]['merged_full_text_cleaned']\n",
    "    embedding = np.concatenate([wordembed_model.wv[word] for word in course])\n",
    "    padded_embedding = pad_sequences([embedding.reshape(1,-1).T], maxlen=max_len, dtype='float32', padding='post').reshape(1, max_len)\n",
    "    return padded_embedding\n",
    "\n",
    "similarity_matrix = np.zeros((Dataset_cleaned.shape[0], Dataset_cleaned.shape[0]))\n",
    "embeddings_matrix = np.vstack([get_padded_embedding(course_id) for course_id in Dataset_cleaned.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = cosine_similarity(embeddings_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "similarity_df = pd.DataFrame(similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_df.to_pickle('quantia_similarities_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.278971</td>\n",
       "      <td>0.180677</td>\n",
       "      <td>0.287668</td>\n",
       "      <td>0.197935</td>\n",
       "      <td>0.235930</td>\n",
       "      <td>0.208269</td>\n",
       "      <td>0.196334</td>\n",
       "      <td>0.157034</td>\n",
       "      <td>0.154573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.270735</td>\n",
       "      <td>0.209542</td>\n",
       "      <td>0.191927</td>\n",
       "      <td>0.184857</td>\n",
       "      <td>0.137248</td>\n",
       "      <td>0.149901</td>\n",
       "      <td>0.136392</td>\n",
       "      <td>0.227976</td>\n",
       "      <td>0.230118</td>\n",
       "      <td>0.117364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.278971</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.192188</td>\n",
       "      <td>0.193533</td>\n",
       "      <td>0.217341</td>\n",
       "      <td>0.137279</td>\n",
       "      <td>0.317228</td>\n",
       "      <td>0.209457</td>\n",
       "      <td>0.153039</td>\n",
       "      <td>0.072313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.313900</td>\n",
       "      <td>0.173985</td>\n",
       "      <td>0.195102</td>\n",
       "      <td>0.166189</td>\n",
       "      <td>0.071647</td>\n",
       "      <td>0.083606</td>\n",
       "      <td>0.199224</td>\n",
       "      <td>0.182241</td>\n",
       "      <td>0.174049</td>\n",
       "      <td>0.278298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.180677</td>\n",
       "      <td>0.192188</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.263691</td>\n",
       "      <td>0.223209</td>\n",
       "      <td>0.201501</td>\n",
       "      <td>0.212920</td>\n",
       "      <td>0.208233</td>\n",
       "      <td>0.279908</td>\n",
       "      <td>0.190325</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136481</td>\n",
       "      <td>0.205696</td>\n",
       "      <td>0.403386</td>\n",
       "      <td>0.227267</td>\n",
       "      <td>0.195775</td>\n",
       "      <td>0.179364</td>\n",
       "      <td>0.237407</td>\n",
       "      <td>0.222848</td>\n",
       "      <td>0.352189</td>\n",
       "      <td>0.173761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.287668</td>\n",
       "      <td>0.193533</td>\n",
       "      <td>0.263691</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.203296</td>\n",
       "      <td>0.233251</td>\n",
       "      <td>0.262025</td>\n",
       "      <td>0.191300</td>\n",
       "      <td>0.175098</td>\n",
       "      <td>0.204174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105117</td>\n",
       "      <td>0.244414</td>\n",
       "      <td>0.265420</td>\n",
       "      <td>0.192289</td>\n",
       "      <td>0.201152</td>\n",
       "      <td>0.131818</td>\n",
       "      <td>0.177756</td>\n",
       "      <td>0.300850</td>\n",
       "      <td>0.396247</td>\n",
       "      <td>0.121749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.197935</td>\n",
       "      <td>0.217341</td>\n",
       "      <td>0.223209</td>\n",
       "      <td>0.203296</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.355751</td>\n",
       "      <td>0.310748</td>\n",
       "      <td>0.921402</td>\n",
       "      <td>0.269088</td>\n",
       "      <td>0.157213</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156835</td>\n",
       "      <td>0.511601</td>\n",
       "      <td>0.212344</td>\n",
       "      <td>0.266452</td>\n",
       "      <td>0.165548</td>\n",
       "      <td>0.254130</td>\n",
       "      <td>0.274017</td>\n",
       "      <td>0.618540</td>\n",
       "      <td>0.269824</td>\n",
       "      <td>0.185984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  1.000000  0.278971  0.180677  0.287668  0.197935  0.235930  0.208269   \n",
       "1  0.278971  1.000000  0.192188  0.193533  0.217341  0.137279  0.317228   \n",
       "2  0.180677  0.192188  1.000000  0.263691  0.223209  0.201501  0.212920   \n",
       "3  0.287668  0.193533  0.263691  1.000000  0.203296  0.233251  0.262025   \n",
       "4  0.197935  0.217341  0.223209  0.203296  1.000000  0.355751  0.310748   \n",
       "\n",
       "         7         8         9   ...        46        47        48        49  \\\n",
       "0  0.196334  0.157034  0.154573  ...  0.270735  0.209542  0.191927  0.184857   \n",
       "1  0.209457  0.153039  0.072313  ...  0.313900  0.173985  0.195102  0.166189   \n",
       "2  0.208233  0.279908  0.190325  ...  0.136481  0.205696  0.403386  0.227267   \n",
       "3  0.191300  0.175098  0.204174  ...  0.105117  0.244414  0.265420  0.192289   \n",
       "4  0.921402  0.269088  0.157213  ...  0.156835  0.511601  0.212344  0.266452   \n",
       "\n",
       "         50        51        52        53        54        55  \n",
       "0  0.137248  0.149901  0.136392  0.227976  0.230118  0.117364  \n",
       "1  0.071647  0.083606  0.199224  0.182241  0.174049  0.278298  \n",
       "2  0.195775  0.179364  0.237407  0.222848  0.352189  0.173761  \n",
       "3  0.201152  0.131818  0.177756  0.300850  0.396247  0.121749  \n",
       "4  0.165548  0.254130  0.274017  0.618540  0.269824  0.185984  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_course_similarity = similarity_df.loc[0]\n",
    "top_10_similar_courses = target_course_similarity.sort_values(ascending=False).head(11)[1:]\n",
    "target_course_Headline = Dataset_cleaned.loc[0,'HEADLINE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_course_similarity = similarity_df.loc[0]\n",
    "top_10_similar_courses = target_course_similarity.sort_values(ascending=False).head(11)[1:]\n",
    "top_10_similar_courses_indices = top_10_similar_courses.index\n",
    "top_10_course_headlines = Dataset_cleaned.loc[top_10_similar_courses_indices, 'HEADLINE']\n",
    "\n",
    "similarity_dict = {headline: similarity for headline, similarity in zip(top_10_course_headlines, top_10_similar_courses)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42    0.517341\n",
       "41    0.498950\n",
       "20    0.483390\n",
       "44    0.431700\n",
       "33    0.429808\n",
       "16    0.412776\n",
       "18    0.410830\n",
       "23    0.397779\n",
       "35    0.395533\n",
       "30    0.377927\n",
       "Name: 0, dtype: float32"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10_similar_courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index                                                                         0\n",
      "HEADLINE                                  66 yo w/ Chronic, Worsening Foot Pain\n",
      "DESCRIPTION                   Which of the following findings are demonstrat...\n",
      "CORE_CONTENT                                                                NaN\n",
      "HEADLINE_Lowercased                       66 yo w/ chronic, worsening foot pain\n",
      "DESCRIPTION_Lowercased        which of the following findings are demonstrat...\n",
      "HEADLINE_tokens                 [66, yo, w/, chronic, ,, worsening, foot, pain]\n",
      "DESCRIPTION_tokens            [which, of, the, following, findings, are, dem...\n",
      "HEADLINE_noStop                 [66, yo, w/, chronic, ,, worsening, foot, pain]\n",
      "DESCRIPTION_noStop            [following, findings, demonstrated, radiograph...\n",
      "HEADLINE_lemmatized             [66, yo, w/, chronic, ,, worsening, foot, pain]\n",
      "DESCRIPTION_lemmatized        [following, finding, demonstrated, radiograph,...\n",
      "merged_full_text              66 yo w/ chronic , worsening foot pain followi...\n",
      "merged_full_text_tokenized    [66, yo, w/, chronic, ,, worsening, foot, pain...\n",
      "merged_full_text_cleaned      [66, yo, w, chronic, , worsening, foot, pain, ...\n",
      "Name: 0, dtype: object\n",
      "index                                                                        59\n",
      "HEADLINE                      Frequent Users of Emergency Departments: Myths...\n",
      "DESCRIPTION                   Frequent users are common in many EDs. In this...\n",
      "CORE_CONTENT                  Jesse M. Pines, MD, MBA, MSCEDirector, Office ...\n",
      "HEADLINE_Lowercased           frequent users of emergency departments: myths...\n",
      "DESCRIPTION_Lowercased        frequent users are common in many eds. in this...\n",
      "HEADLINE_tokens               [frequent, users, of, emergency, departments, ...\n",
      "DESCRIPTION_tokens            [frequent, users, are, common, in, many, eds, ...\n",
      "HEADLINE_noStop               [frequent, users, emergency, departments, :, m...\n",
      "DESCRIPTION_noStop            [frequent, users, common, many, eds, ., presen...\n",
      "HEADLINE_lemmatized           [frequent, user, emergency, department, :, myt...\n",
      "DESCRIPTION_lemmatized        [frequent, user, common, many, ed, ., presenta...\n",
      "merged_full_text              frequent user emergency department : myth real...\n",
      "merged_full_text_tokenized    [frequent, user, emergency, department, :, myt...\n",
      "merged_full_text_cleaned      [frequent, user, emergency, department, , myth...\n",
      "Name: 42, dtype: object\n",
      "index                                                                        58\n",
      "HEADLINE                                    5 wo Infant w/ Difficulty Breathing\n",
      "DESCRIPTION                   What is the leading differential diagnosis? Cy...\n",
      "CORE_CONTENT                          Gregory Ball, MD, PhDDiagnostic Radiology\n",
      "HEADLINE_Lowercased                         5 wo infant w/ difficulty breathing\n",
      "DESCRIPTION_Lowercased        what is the leading differential diagnosis? cy...\n",
      "HEADLINE_tokens                      [5, wo, infant, w/, difficulty, breathing]\n",
      "DESCRIPTION_tokens            [what, is, the, leading, differential, diagnos...\n",
      "HEADLINE_noStop                      [5, wo, infant, w/, difficulty, breathing]\n",
      "DESCRIPTION_noStop            [leading, differential, diagnosis, ?, cystic, ...\n",
      "HEADLINE_lemmatized                  [5, wo, infant, w/, difficulty, breathing]\n",
      "DESCRIPTION_lemmatized        [leading, differential, diagnosis, ?, cystic, ...\n",
      "merged_full_text              5 wo infant w/ difficulty breathing leading di...\n",
      "merged_full_text_tokenized    [5, wo, infant, w/, difficulty, breathing, lea...\n",
      "merged_full_text_cleaned      [5, wo, infant, w, difficulty, breathing, lead...\n",
      "Name: 41, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(Dataset_cleaned.loc[0])\n",
    "print(Dataset_cleaned.loc[42])\n",
    "print(Dataset_cleaned.loc[41])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>HEADLINE</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>CORE_CONTENT</th>\n",
       "      <th>HEADLINE_Lowercased</th>\n",
       "      <th>DESCRIPTION_Lowercased</th>\n",
       "      <th>HEADLINE_tokens</th>\n",
       "      <th>DESCRIPTION_tokens</th>\n",
       "      <th>HEADLINE_noStop</th>\n",
       "      <th>DESCRIPTION_noStop</th>\n",
       "      <th>HEADLINE_lemmatized</th>\n",
       "      <th>DESCRIPTION_lemmatized</th>\n",
       "      <th>merged_full_text</th>\n",
       "      <th>merged_full_text_tokenized</th>\n",
       "      <th>merged_full_text_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>66 yo w/ Chronic, Worsening Foot Pain</td>\n",
       "      <td>Which of the following findings are demonstrat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66 yo w/ chronic, worsening foot pain</td>\n",
       "      <td>which of the following findings are demonstrat...</td>\n",
       "      <td>[66, yo, w/, chronic, ,, worsening, foot, pain]</td>\n",
       "      <td>[which, of, the, following, findings, are, dem...</td>\n",
       "      <td>[66, yo, w/, chronic, ,, worsening, foot, pain]</td>\n",
       "      <td>[following, findings, demonstrated, radiograph...</td>\n",
       "      <td>[66, yo, w/, chronic, ,, worsening, foot, pain]</td>\n",
       "      <td>[following, finding, demonstrated, radiograph,...</td>\n",
       "      <td>66 yo w/ chronic , worsening foot pain followi...</td>\n",
       "      <td>[66, yo, w/, chronic, ,, worsening, foot, pain...</td>\n",
       "      <td>[66, yo, w, chronic, , worsening, foot, pain, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Bloody Stools in the NICU</td>\n",
       "      <td>What is your differential diagnosis? Necrotizi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bloody stools in the nicu</td>\n",
       "      <td>what is your differential diagnosis? necrotizi...</td>\n",
       "      <td>[bloody, stools, in, the, nicu]</td>\n",
       "      <td>[what, is, your, differential, diagnosis, ?, n...</td>\n",
       "      <td>[bloody, stools, nicu]</td>\n",
       "      <td>[differential, diagnosis, ?, necrotizing, ente...</td>\n",
       "      <td>[bloody, stool, nicu]</td>\n",
       "      <td>[differential, diagnosis, ?, necrotizing, ente...</td>\n",
       "      <td>bloody stool nicu differential diagnosis ? nec...</td>\n",
       "      <td>[bloody, stool, nicu, differential, diagnosis,...</td>\n",
       "      <td>[bloody, stool, nicu, differential, diagnosis,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Erectile Dysfunction and Cardiovascular Risk</td>\n",
       "      <td>Expert presentation on erectile dysfunction an...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>erectile dysfunction and cardiovascular risk</td>\n",
       "      <td>expert presentation on erectile dysfunction an...</td>\n",
       "      <td>[erectile, dysfunction, and, cardiovascular, r...</td>\n",
       "      <td>[expert, presentation, on, erectile, dysfuncti...</td>\n",
       "      <td>[erectile, dysfunction, cardiovascular, risk]</td>\n",
       "      <td>[expert, presentation, erectile, dysfunction, ...</td>\n",
       "      <td>[erectile, dysfunction, cardiovascular, risk]</td>\n",
       "      <td>[expert, presentation, erectile, dysfunction, ...</td>\n",
       "      <td>erectile dysfunction cardiovascular risk exper...</td>\n",
       "      <td>[erectile, dysfunction, cardiovascular, risk, ...</td>\n",
       "      <td>[erectile, dysfunction, cardiovascular, risk, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Cost Effectiveness in Sexual Medicine – Tales ...</td>\n",
       "      <td>Case presentation on the erectile dysfucntion ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cost effectiveness in sexual medicine – tales ...</td>\n",
       "      <td>case presentation on the erectile dysfucntion ...</td>\n",
       "      <td>[cost, effectiveness, in, sexual, medicine, –,...</td>\n",
       "      <td>[case, presentation, on, the, erectile, dysfuc...</td>\n",
       "      <td>[cost, effectiveness, sexual, medicine, –, tal...</td>\n",
       "      <td>[case, presentation, erectile, dysfucntion, ca...</td>\n",
       "      <td>[cost, effectiveness, sexual, medicine, –, tal...</td>\n",
       "      <td>[case, presentation, erectile, dysfucntion, ca...</td>\n",
       "      <td>cost effectiveness sexual medicine – tale clin...</td>\n",
       "      <td>[cost, effectiveness, sexual, medicine, –, tal...</td>\n",
       "      <td>[cost, effectiveness, sexual, medicine, , tale...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>A 46 year old lady with joint pain</td>\n",
       "      <td>An image challenge on a 46 year old lady with ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a 46 year old lady with joint pain</td>\n",
       "      <td>an image challenge on a 46 year old lady with ...</td>\n",
       "      <td>[a, 46, year, old, lady, with, joint, pain]</td>\n",
       "      <td>[an, image, challenge, on, a, 46, year, old, l...</td>\n",
       "      <td>[46, year, old, lady, joint, pain]</td>\n",
       "      <td>[image, challenge, 46, year, old, lady, joint,...</td>\n",
       "      <td>[46, year, old, lady, joint, pain]</td>\n",
       "      <td>[image, challenge, 46, year, old, lady, joint,...</td>\n",
       "      <td>46 year old lady joint pain image challenge 46...</td>\n",
       "      <td>[46, year, old, lady, joint, pain, image, chal...</td>\n",
       "      <td>[46, year, old, lady, joint, pain, image, chal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                           HEADLINE  \\\n",
       "0      0              66 yo w/ Chronic, Worsening Foot Pain   \n",
       "1      1                          Bloody Stools in the NICU   \n",
       "2      2       Erectile Dysfunction and Cardiovascular Risk   \n",
       "3      3  Cost Effectiveness in Sexual Medicine – Tales ...   \n",
       "4      4                 A 46 year old lady with joint pain   \n",
       "\n",
       "                                         DESCRIPTION CORE_CONTENT  \\\n",
       "0  Which of the following findings are demonstrat...          NaN   \n",
       "1  What is your differential diagnosis? Necrotizi...          NaN   \n",
       "2  Expert presentation on erectile dysfunction an...          NaN   \n",
       "3  Case presentation on the erectile dysfucntion ...          NaN   \n",
       "4  An image challenge on a 46 year old lady with ...          NaN   \n",
       "\n",
       "                                 HEADLINE_Lowercased  \\\n",
       "0              66 yo w/ chronic, worsening foot pain   \n",
       "1                          bloody stools in the nicu   \n",
       "2       erectile dysfunction and cardiovascular risk   \n",
       "3  cost effectiveness in sexual medicine – tales ...   \n",
       "4                 a 46 year old lady with joint pain   \n",
       "\n",
       "                              DESCRIPTION_Lowercased  \\\n",
       "0  which of the following findings are demonstrat...   \n",
       "1  what is your differential diagnosis? necrotizi...   \n",
       "2  expert presentation on erectile dysfunction an...   \n",
       "3  case presentation on the erectile dysfucntion ...   \n",
       "4  an image challenge on a 46 year old lady with ...   \n",
       "\n",
       "                                     HEADLINE_tokens  \\\n",
       "0    [66, yo, w/, chronic, ,, worsening, foot, pain]   \n",
       "1                    [bloody, stools, in, the, nicu]   \n",
       "2  [erectile, dysfunction, and, cardiovascular, r...   \n",
       "3  [cost, effectiveness, in, sexual, medicine, –,...   \n",
       "4        [a, 46, year, old, lady, with, joint, pain]   \n",
       "\n",
       "                                  DESCRIPTION_tokens  \\\n",
       "0  [which, of, the, following, findings, are, dem...   \n",
       "1  [what, is, your, differential, diagnosis, ?, n...   \n",
       "2  [expert, presentation, on, erectile, dysfuncti...   \n",
       "3  [case, presentation, on, the, erectile, dysfuc...   \n",
       "4  [an, image, challenge, on, a, 46, year, old, l...   \n",
       "\n",
       "                                     HEADLINE_noStop  \\\n",
       "0    [66, yo, w/, chronic, ,, worsening, foot, pain]   \n",
       "1                             [bloody, stools, nicu]   \n",
       "2      [erectile, dysfunction, cardiovascular, risk]   \n",
       "3  [cost, effectiveness, sexual, medicine, –, tal...   \n",
       "4                 [46, year, old, lady, joint, pain]   \n",
       "\n",
       "                                  DESCRIPTION_noStop  \\\n",
       "0  [following, findings, demonstrated, radiograph...   \n",
       "1  [differential, diagnosis, ?, necrotizing, ente...   \n",
       "2  [expert, presentation, erectile, dysfunction, ...   \n",
       "3  [case, presentation, erectile, dysfucntion, ca...   \n",
       "4  [image, challenge, 46, year, old, lady, joint,...   \n",
       "\n",
       "                                 HEADLINE_lemmatized  \\\n",
       "0    [66, yo, w/, chronic, ,, worsening, foot, pain]   \n",
       "1                              [bloody, stool, nicu]   \n",
       "2      [erectile, dysfunction, cardiovascular, risk]   \n",
       "3  [cost, effectiveness, sexual, medicine, –, tal...   \n",
       "4                 [46, year, old, lady, joint, pain]   \n",
       "\n",
       "                              DESCRIPTION_lemmatized  \\\n",
       "0  [following, finding, demonstrated, radiograph,...   \n",
       "1  [differential, diagnosis, ?, necrotizing, ente...   \n",
       "2  [expert, presentation, erectile, dysfunction, ...   \n",
       "3  [case, presentation, erectile, dysfucntion, ca...   \n",
       "4  [image, challenge, 46, year, old, lady, joint,...   \n",
       "\n",
       "                                    merged_full_text  \\\n",
       "0  66 yo w/ chronic , worsening foot pain followi...   \n",
       "1  bloody stool nicu differential diagnosis ? nec...   \n",
       "2  erectile dysfunction cardiovascular risk exper...   \n",
       "3  cost effectiveness sexual medicine – tale clin...   \n",
       "4  46 year old lady joint pain image challenge 46...   \n",
       "\n",
       "                          merged_full_text_tokenized  \\\n",
       "0  [66, yo, w/, chronic, ,, worsening, foot, pain...   \n",
       "1  [bloody, stool, nicu, differential, diagnosis,...   \n",
       "2  [erectile, dysfunction, cardiovascular, risk, ...   \n",
       "3  [cost, effectiveness, sexual, medicine, –, tal...   \n",
       "4  [46, year, old, lady, joint, pain, image, chal...   \n",
       "\n",
       "                            merged_full_text_cleaned  \n",
       "0  [66, yo, w, chronic, , worsening, foot, pain, ...  \n",
       "1  [bloody, stool, nicu, differential, diagnosis,...  \n",
       "2  [erectile, dysfunction, cardiovascular, risk, ...  \n",
       "3  [cost, effectiveness, sexual, medicine, , tale...  \n",
       "4  [46, year, old, lady, joint, pain, image, chal...  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 15)\n"
     ]
    }
   ],
   "source": [
    "Dataset_cleaned = Dataset_cleaned.drop_duplicates(subset='merged_full_text')\n",
    "print(Dataset_cleaned.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_cleaned.to_pickle('quantia_dataset_cleaned.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 yo w/ chronic , worsening foot pain following finding demonstrated radiograph ? dense tophus , erosion fifth metatarsophalangeal joint , sausage digit , tarsal bone fusion , lytic osseous lesion sclerotic rim\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Abirr\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3628\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3629\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3630\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Abirr\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Abirr\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 64",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12132\\95321074.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDataset_cleaned\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'merged_full_text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDataset_cleaned\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'merged_full_text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDataset_cleaned\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m117\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'merged_full_text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Abirr\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    958\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    959\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 960\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    961\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Abirr\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_get_value\u001b[1;34m(self, index, col, takeable)\u001b[0m\n\u001b[0;32m   3620\u001b[0m             \u001b[1;31m#  results if our categories are integers that dont match our codes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3621\u001b[0m             \u001b[1;31m# IntervalIndex: IntervalTree has no get_loc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3622\u001b[1;33m             \u001b[0mrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3623\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mseries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3624\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Abirr\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3629\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3630\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3631\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3632\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3633\u001b[0m                 \u001b[1;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 64"
     ]
    }
   ],
   "source": [
    "print(Dataset_cleaned.loc[0,'merged_full_text'])\n",
    "print(Dataset_cleaned.loc[64,'merged_full_text'])\n",
    "print(Dataset_cleaned.loc[117,'merged_full_text'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This below is just the whole thing together for a single course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Get the embeddings for each course title and description\n",
    "target_course = preprocessed_df.loc[preprocessed_df['CourseId'] == 'objective-c']['title_desc_cleaned'].tolist()\n",
    "target_embedding = np.concatenate([wordembed_model.wv[word] for word in target_course])\n",
    "max_len = max([len(np.concatenate([wordembed_model.wv[word] for word in row['title_desc_cleaned']])) for _, row in preprocessed_df.iterrows()])\n",
    "\n",
    "target_embedding_padded = pad_sequences([target_embedding.reshape(1,-1).T], maxlen=max_len, dtype='float32', padding='post')\n",
    "target_embedding_padded = target_embedding_padded.reshape(1,max_len)\n",
    "\n",
    "# Compute the similarity scores between the target course and all other courses in the dataset\n",
    "similarity_scores = {}\n",
    "for index, row in preprocessed_df.iterrows():\n",
    "    course_id = row['CourseId']\n",
    "    course_title_desc = row['title_desc_cleaned']\n",
    "    course_embedding = np.concatenate([wordembed_model.wv[word] for word in course_title_desc])\n",
    "\n",
    "    course_embedding_padded = pad_sequences([course_embedding], maxlen=max_len, dtype='float32', padding='post').reshape(1,max_len)\n",
    "    similarity_scores[course_id] = cosine_similarity(target_embedding_padded, course_embedding_padded)[0][0]\n",
    "    \n",
    "# Sort the courses by similarity score and return the top n courses\n",
    "similar_courses = sorted(similarity_scores.items(), key=lambda x: x[1], reverse=True)[:20]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is for the articles data, we want to convert it to csv and try & clean it later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully made csv file\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tsv_file='msd_manual.tsv'\n",
    "\n",
    "# reading given tsv file\n",
    "tsv_table=pd.read_table(tsv_file,sep='\\t')\n",
    "\n",
    "# converting tsv file into csv\n",
    "tsv_table.to_csv('msd_manual.csv',index=False)\n",
    "\n",
    "# output\n",
    "print(\"Successfully made csv file\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
